{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing with Neural Network\n",
    "\n",
    "## Session 19b: Simple RNN\n",
    "- Weather Data \n",
    "- Multiple features\n",
    "\n",
    "<img src='../../../images/prasami_color_tutorials_small.png' width='400' alt=\"By Pramod Sharma : pramod.sharma@prasami.com\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-----------------\n",
    "### Import Libraries\n",
    "###-----------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.helper import fn_plot_tf_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----------------------\n",
    "### Some basic parameters\n",
    "###----------------------\n",
    "\n",
    "inpDir = '../../../input' # location where input data is stored\n",
    "outDir = '../output' # location to store outputs\n",
    "\n",
    "RANDOM_STATE = 24 # for initialization ----- REMEMBER: to remove at the time of promotion to production\n",
    "np.random.seed(RANDOM_STATE) # Set Random Seed for reproducible results\n",
    "tf.random.set_seed(RANDOM_STATE) # setting for Tensorflow as well\n",
    "\n",
    "EPOCHS = 200  # number of cycles to run\n",
    "ALPHA = 0.001  # learning rate\n",
    "TEST_SIZE = 0.2 # What fraction we want to keep for testing\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 20\n",
    "LR_PATIENCE = 10\n",
    "LR_FACTOR = 0.1\n",
    "\n",
    "# Set parameters for decoration of plots\n",
    "params = {'legend.fontsize' : 'large',\n",
    "          'figure.figsize'  : (12,9),\n",
    "          'axes.labelsize'  : 'x-large',\n",
    "          'axes.titlesize'  :'x-large',\n",
    "          'xtick.labelsize' :'large',\n",
    "          'ytick.labelsize' :'large',\n",
    "         }\n",
    "CMAP = plt.cm.coolwarm\n",
    "\n",
    "plt.rcParams.update(params) # update rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings so that Tensorflow can not Hog all the GPU memory\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Weather Data\n",
    "Source: [Kaggle](https://www.kaggle.com/muthuj7/weather-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataFilename = 'weatherHistory.csv'\n",
    "data_df = pd.read_csv(os.path.join(inpDir, dataFilename))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in data_df.columns:\n",
    "    print(f'{col} : {data_df[col].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Precip Type has nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[data_df['Precip Type'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Precip Type'] = data_df['Precip Type'].fillna('No')\n",
    "data_df[data_df['Precip Type'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Summary', 'Precip Type']\n",
    "\n",
    "for count, col in enumerate(cat_cols):\n",
    "                           \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    colCount = data_df[col].value_counts()\n",
    "        \n",
    "    ax.set_title(col)\n",
    "    \n",
    "    ax.set_xlabel('Frequency')\n",
    "    \n",
    "    #sns.countplot(data_df, y = col, ax = ax)\n",
    "    sns.histplot(data_df, y = col, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Temperature (C)', 'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)', \n",
    "            'Wind Bearing (degrees)', 'Visibility (km)', 'Pressure (millibars)']\n",
    "fig, axes = plt.subplots(2,4)\n",
    "\n",
    "axes = axes.ravel()\n",
    "\n",
    "for count, col in enumerate(num_cols):\n",
    "    \n",
    "    ax =axes[count]\n",
    "    \n",
    "    sns.histplot(data_df, x = col, ax = ax, bins = 50)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df['Pressure (millibars)']<500] ['Precip Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate class\n",
    "classmeans = data_df.pivot_table('Pressure (millibars)', columns='Precip Type', aggfunc='mean')\n",
    "classmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df['Pressure (millibars)'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Pressure (millibars)'].replace(0, np.nan, inplace=True)\n",
    "data_df.loc[data_df['Pressure (millibars)'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Pressure (millibars)'] = data_df[['Pressure (millibars)', 'Precip Type']].apply(\n",
    "    lambda x: classmeans['rain']['Pressure (millibars)'] if pd.isnull(x['Pressure (millibars)']) else\n",
    "    x['Pressure (millibars)'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[data_df['Pressure (millibars)'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[['Precip Type', 'Temperature (C)']].groupby(['Precip Type'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Temperature (C)','Apparent Temperature (C)',\n",
    " 'Humidity',\n",
    " 'Wind Speed (km/h)',\n",
    " 'Wind Bearing (degrees)',\n",
    " 'Visibility (km)',\n",
    " 'Pressure (millibars)']\n",
    "\n",
    "fig, axes = plt.subplots(2,4)\n",
    "\n",
    "axes = axes.ravel()\n",
    "\n",
    "for count, col in enumerate(num_cols):\n",
    "    sns.boxplot(y=col, data=data_df, ax = axes[count])\n",
    "\n",
    "plt.tight_layout()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[num_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data_df[num_cols].corr(), annot=True, cmap=plt.cm.Blues, linewidths = .2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- We can drop Summary , Loud Cover, and Daily Summary columns\n",
    "- Pressure has some 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['datetime'] = pd.to_datetime(data_df['Formatted Date'], \n",
    "                                     utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['Daily Summary', 'Summary', 'Loud Cover', 'Wind Speed (km/h)', 'Wind Bearing (degrees)','Formatted Date'\t]\n",
    "data_df = data_df.drop(drop_columns, axis = 1)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_df['Precip Type'] = le.fit_transform(data_df['Precip Type'])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = data_df.copy()\n",
    "tmp_df = tmp_df.sort_values('datetime', axis=0, ascending=True)\n",
    "tmp_df = tmp_df.reset_index(drop=True)\n",
    "tmp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = tmp_df.rename({'Temperature (C)': 'temp',\n",
    "                        'Apparent Temperature (C)':'app_t',\n",
    "                        'Humidity': 'hum',\n",
    "                        'Pressure (millibars)': 'pres',\n",
    "                        'Precip Type': 'precip', \n",
    "                        'Visibility (km)': 'vis'\t}, axis=1)\n",
    "tmp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment un-comment following lines if you want part or full dataset\n",
    "\n",
    "#startDate = pd.to_datetime('2007-1-1', utc=True)\n",
    "#endDate = pd.to_datetime('2008-1-1', utc=True)\n",
    "#temp_df = temp_df[(temp_df['datetime']  >= startDate) & (temp_df['datetime']  < endDate)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,10))\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 1)\n",
    "tmp_df.plot(x='datetime', y='temp', style=\".\", ax = ax);\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 2)\n",
    "tmp_df.plot(x='datetime', y='app_t', style=\".\", ax = ax);\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 3)\n",
    "tmp_df.plot(x='datetime', y='hum', style=\".\", ax = ax);\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 4)\n",
    "tmp_df.plot(x='datetime', y='vis', style=\".\", ax = ax);\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 5)\n",
    "tmp_df.plot(x='datetime', y='pres', style=\".\", ax = ax);\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 6)\n",
    "tmp_df.plot(x='datetime', y='precip', style=\".\", ax = ax);\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_idx = np.arange(time_step, tmp_df.shape[0], time_step)\n",
    "y_df = tmp_df.iloc[y_idx][['temp', 'datetime']]\n",
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Limit it to complete days\n",
    "\n",
    "tmp_df = tmp_df.iloc[range(len(y_df) * time_step)]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df['temp'].shape, tmp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = np.reshape(tmp_df['temp'].to_numpy(), (y_df.shape[0], time_step))\n",
    "X_at = np.reshape(tmp_df['app_t'].to_numpy(), (y_df.shape[0], time_step))\n",
    "X_hum = np.reshape(tmp_df['hum'].to_numpy(), (y_df.shape[0], time_step))\n",
    "X_precip = np.reshape(tmp_df['precip'].to_numpy(), (y_df.shape[0], time_step))\n",
    "X_vis = np.reshape(tmp_df['vis'].to_numpy(), (y_df.shape[0], time_step))\n",
    "X_pres = np.reshape(tmp_df['pres'].to_numpy(), (y_df.shape[0], time_step))\n",
    "X_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 23 cols only \n",
    "X_temp = X_temp[:, :23]\n",
    "X_at = X_at[:, :23]\n",
    "X_hum = X_hum[:, :23]\n",
    "X_precip = X_precip[:, :23]\n",
    "X_vis = X_vis[:, :23]\n",
    "X_pres = X_pres[:, :23]\n",
    "X_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "Need to reshape the inputs into the 3D format as expected by the SimpleRNNs, namely [samples, timesteps, features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with what features you want to use\n",
    "X_data = np.stack((X_temp, \n",
    "                   X_at , \n",
    "                   X_hum , \n",
    "                   #X_precip, \n",
    "                   #X_vis, \n",
    "                   #X_pres\n",
    "                  ), axis = 2)\n",
    "#X_data = np.reshape(X_temp, (X_temp.shape[0], X_temp.shape[1], 1))\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(y_df.shape[0] * (1-TEST_SIZE))\n",
    "X_train = X_data[:split]\n",
    "X_test = X_data[split:]\n",
    "y_train = y_df['temp'].values[:split]\n",
    "y_test = y_df['temp'].values[split:]\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_units = 64 # number of units in the RNN\n",
    "\n",
    "input_shape=(time_step-1, X_train.shape[2] ) # we are using five features\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Input(input_shape))\n",
    "\n",
    "model.add(tf.keras.layers.SimpleRNN(units = h_units, \n",
    "                                    activation = 'tanh'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', \n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                                           patience=PATIENCE,\n",
    "                                                           mode='auto',\n",
    "                                                           baseline =None,\n",
    "                                                           restore_best_weights=True)\n",
    "\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                 factor=LR_FACTOR,\n",
    "                                                 patience=LR_PATIENCE,\n",
    "                                                 verbose=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size= BATCH_SIZE, \n",
    "                    verbose=2,\n",
    "                    callbacks = [early_stopping_callback, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df = hist_df.rename({'root_mean_squared_error': 'rmse', 'val_root_mean_squared_error' : 'val_rmse'}, axis=1)\n",
    "\n",
    "\n",
    "fn_plot_tf_hist(hist_df)\n",
    "#.8172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_pred = np.append(y_train_pred, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = y_df.copy()\n",
    "res_df['pred'] = y_pred\n",
    "res_df['datetime'] = res_df['datetime'].dt.date\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,6))\n",
    "\n",
    "res_df.plot(x='datetime', y=['temp','pred'], ax = ax);\n",
    "\n",
    "ax.vlines(res_df.iloc[X_train.shape[0]]['datetime'], \n",
    "          res_df['temp'].min(), \n",
    "          res_df['temp'].max(), color = 'k', \n",
    "          linewidth=3.0, zorder=10, alpha =0.8)\n",
    "\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
